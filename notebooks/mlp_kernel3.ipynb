{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_close_flat(a, b):\n",
    "    return torch.allclose(a.flatten(), b.flatten(), atol=1e-6, rtol=1e-6), (a - b)\n",
    "\n",
    "def check(a, b, string):\n",
    "    print(string, a.shape)\n",
    "    print(len(string) * ' ', b.shape)\n",
    "    # all_close_flat(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias = True, padding_mode='zeros'):\n",
    "        super().__init__()\n",
    "        assert padding_mode in ['zeros', 'circular']\n",
    "        if padding_mode == 'zeros':\n",
    "            padding_mode = 'constant'\n",
    "        assert padding == (kernel_size - 1) // 2\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride=stride\n",
    "        self.padding = padding\n",
    "        self.bias = bias\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "        self.weights = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size))\n",
    "        self.biases = nn.Parameter(torch.randn(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, in_channels2, width = x.shape\n",
    "        assert in_channels2 == self.in_channels\n",
    "\n",
    "        \n",
    "        x_pad = F.pad(x, (self.padding, self.padding), mode=self.padding_mode)\n",
    "\n",
    "        patches = x_pad.unsqueeze(2).unfold(3, self.kernel_size, 1)\n",
    "\n",
    "        patches = patches.contiguous().view(batch_size, self.in_channels, width, self.kernel_size)\n",
    "\n",
    "        # Shift the windows into the batch dimension using permute\n",
    "        patches = patches.permute(0, 2, 1, 3) # # batch_size, width, channels, kernel_size \n",
    "\n",
    "        # Multiply the patches with the weights in order to calculate the conv\n",
    "        # out = (patches.unsqueeze(2) * self.weights.unsqueeze(0)).sum([3, 4])\n",
    "        # patches_unsqueezed = patches.unsqueeze(2) # batch_size, 1, width, channels, kernel_size\n",
    "        # weights_unsqueezed = self.weights.unsqueeze(0) # 1, out_channels, in_channels, kernel_size\n",
    "        # out = patches_unsqueezed * weights_unsqueezed\n",
    "        # print(patches_unsqueezed.shape, weights_unsqueezed.shape, out.shape)\n",
    "        # torch.Size([2, 10, 1, 4, 3]) torch.Size([1, 6, 4, 3]) torch.Size([2, 10, 6, 4, 3])\n",
    "        # print(patches.shape, self.weights.shape, out.shape)\n",
    "        # torch.Size([2, 10, 4, 3]) torch.Size([6, 4, 3]) torch.Size([2, 10, 6, 4, 3])\n",
    "        # out = out.sum([3, 4]) # batch_size, out_channels, width, channels\n",
    "        # torch.Size([2, 10, 6])\n",
    "        # print(out.shape)\n",
    "        # out = out.permute(0, 2, 1) # batch_size, out_channels, output_pixels\n",
    "        out = torch.einsum('bwik,oik->bow', patches, self.weights) # (bwik) -> (batch_size, with, in_channels, kernel)\n",
    "\n",
    "        # Add the bias\n",
    "        if self.bias:\n",
    "            out += self.biases.unsqueeze(0).unsqueeze(2)\n",
    "\n",
    "        out = out.view(batch_size, self.out_channels, width)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "batch_size, width = 2, 10\n",
    "in_channels, out_channels = 4, 6\n",
    "kernel_size, stride = 3, 1\n",
    "\n",
    "x = torch.randn(batch_size, in_channels, width)\n",
    "padding = (kernel_size - 1) // 2\n",
    "\n",
    "padding_mode = 'circular'\n",
    "bias = True\n",
    "\n",
    "# Create conv\n",
    "conv_torch = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, bias=bias, padding=padding, padding_mode=padding_mode)\n",
    "out_true = conv_torch(x)\n",
    "\n",
    "conv_my = MyConv1d(in_channels, out_channels, kernel_size, stride=stride, bias=bias, padding=padding, padding_mode=padding_mode)\n",
    "conv_my.weights = nn.Parameter(conv_torch.weight)\n",
    "conv_my.biases = nn.Parameter(conv_torch.bias)\n",
    "out_my = conv_my(x)\n",
    "\n",
    "assert torch.allclose(out_true, out_my, atol=1e-6, rtol=1e-6)\n",
    "# assert torch.allclose(out_true, out_my) # For some reason, this fails. TODO: Find out why\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sympde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
