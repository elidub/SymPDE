#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=Train
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=08:00:00
#SBATCH --output=jobs/slurm_output/train_%A.out

module purge
module load 2022
module load Anaconda3/2022.05

cd $HOME/thesis/SymPDE/sympde
source activate sympde

pde_name="KdV"
max_epochs=60

for seed in {1..3}
do
    srun python -u run.py \
        --train \
        --pde_name $pde_name \
        --version aug1_${pde_name}_seed$seed \
        --max_epochs $max_epochs --seed $seed \
        --generators \
        --num_workers 20 \
        --n_splits 4000 500 500 \

    srun python -u run.py \
        --train \
        --pde_name $pde_name \
        --version aug0_${pde_name}_seed$seed \
        --max_epochs $max_epochs --seed $seed \
        --num_workers 20 \
        --n_splits 4000 500 500 \

done