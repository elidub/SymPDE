#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=Train
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=02:30:00
#SBATCH --output=jobs/slurm_output/symlie_train_array_%A.out

cd $HOME/thesis/SymPDE/symlie

module purge
module load 2022
module load Anaconda3/2022.05
source activate sympde

srun python -u run.py \
    --num_workers 18 \
    --lr 0.001 --batch_size 16 --n_train 10000 --net TrainP --max_epochs 400 --data_dir ../data/MNIST --eps_mult 0. 0. 1. 1. --grid_size 7 7 --noise_std 0. --n_val 1000 --n_test 1000 --tags mnist long --earlystop
