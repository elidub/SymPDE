#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=Train
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=08:00:00
#SBATCH --output=jobs/slurm_output/lpsda_train_%A.out

module purge
module load 2022
module load Anaconda3/2022.05

cd $HOME/thesis/SymPDE/sympde
source activate sympde

pde_name="KdV"
max_epochs=60

for seed in {1..3}
do
    srun python -u experiments/train.py \
        --experiment=KdV \
        --KdV_augmentation=1,1.0,0.4,0.1 \
        --train_samples=500 \ 
        --suffix=medium \


    srun python -u experiments/train.py \
        --experiment=KdV \
        --KdV_augmentation=0,0.0,0.0,0.0 \
        --train_samples=500 \ 
        --suffix=medium \

done