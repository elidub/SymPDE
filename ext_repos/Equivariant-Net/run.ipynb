{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from run_model import parse_options\n",
    "from evaluation import spectrum_band\n",
    "from models import ResNet, Unet, ResNet_UM, Unet_UM, ResNet_Mag, Unet_Mag, ResNet_Rot, Unet_Rot, ResNet_Scale, Unet_Scale\n",
    "from utils import train_epoch, eval_epoch, test_epoch, Dataset, get_lr, train_epoch_scale, eval_epoch_scale, test_epoch_scale, Dataset_scale\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../sympde/'))\n",
    "from models.model_mag import mag_conv2d, mag_resblock\n",
    "from models.model_noequ import Resblock\n",
    "from misc.equiv import assert_equiv\n",
    "\n",
    "\n",
    "from model.networks.single_sym.magnitude import Conv1dMag, Conv2dMag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_options(notebook=True)\n",
    "args.dataset = 'RBC'\n",
    "args.architecture = 'ResNet'\n",
    "args.symmetry = 'Mag' #'None', 'UM', 'Rot', 'Mag', 'Scale'\n",
    "args.output_length = 3\n",
    "args.learning_rate = 0.001\n",
    "\n",
    "args.batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)  # python random generator\n",
    "np.random.seed(args.seed)  # numpy random generator\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "symmetry = args.symmetry\n",
    "model_name = args.architecture + \"_\" + args.symmetry\n",
    "num_epoch = args.num_epoch\n",
    "learning_rate = args.learning_rate # 0.0005 for mag_equ resnet; 0.0001 for scale_equ resnet\n",
    "batch_size = args.batch_size\n",
    "input_length = args.input_length\n",
    "train_output_length = args.output_length # 4 for all Unets\n",
    "test_output_length = 10\n",
    "kernel_size = args.kernel_size\n",
    "lr_decay = args.decay_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_mag/sample_\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == \"RBC\":\n",
    "    train_direc = \"data_64/sample_\"\n",
    "    valid_direc = \"data_64/sample_\"\n",
    "    train_indices = list(range(0, 6000))\n",
    "    valid_indices = list(range(6000, 8000))\n",
    "\n",
    "    # test on future time steps\n",
    "    test_future_direc = \"data_64/sample_\"\n",
    "    test_future_indices = list(range(8000, 10000)) \n",
    "\n",
    "    # test on data applied with symmetry transformations \n",
    "    test_domain_direc = \"data_64/sample_\" if args.symmetry == \"None\" else \"data_\" + symmetry.lower() + \"/sample_\" \n",
    "    print(test_domain_direc)\n",
    "    test_domain_indices = list(range(8000, 10000)) \n",
    "\n",
    "elif args.dataset == \"Ocean\":\n",
    "    train_direc = \"ocean_train/sample_\"\n",
    "    valid_direc = \"ocean_train/sample_\"\n",
    "    train_indices = list(range(0, 8000))\n",
    "    valid_indices = list(range(8000, 10000))\n",
    "\n",
    "    # test on future time steps\n",
    "    test_future_direc = \"ocean_train/sample_\"\n",
    "    test_future_indices = list(range(10000, 12000)) \n",
    "\n",
    "    # test on data from different domain\n",
    "    test_domain_direc = \"ocean_test/sample_\"\n",
    "    test_domain_indices = list(range(0, 2000)) \n",
    "    \n",
    "else:\n",
    "    print(\"Invalid dataset name entered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if symmetry != \"Scale\":\n",
    "    train_set = Dataset(train_indices, input_length, 30, train_output_length, train_direc, True)\n",
    "    valid_set = Dataset(valid_indices, input_length, 30, train_output_length, valid_direc, True)\n",
    "    test_future_set = Dataset(test_future_indices, input_length, 30, test_output_length, test_future_direc, True)\n",
    "    test_domain_set = Dataset(test_domain_indices, input_length, 30, test_output_length, test_domain_direc, True)\n",
    "else:\n",
    "    # use Dataset_scale for scale equivariant models\n",
    "    train_set = Dataset_scale(train_indices, input_length, 30, train_output_length, train_direc)\n",
    "    valid_set = Dataset_scale(valid_indices, input_length, 30, train_output_length, train_direc)\n",
    "    test_future_set = Dataset_scale(test_future_indices, input_length, 30, test_output_length, test_future_direc)\n",
    "    test_domain_set = Dataset_scale(test_domain_indices, input_length, 30, test_output_length, test_domain_direc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 24, 64, 64]), torch.Size([2, 3, 64, 64]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.load(train_direc + str(1) + \".pt\")\n",
    "x = d[(train_set.mid-train_set.input_length):train_set.mid].transpose(0,1)\n",
    "y = d[train_set.mid:(train_set.mid+train_set.output_length)].transpose(0,1)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 64, 64]) torch.Size([3, 2, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x, y = train_set[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 8, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = batch_size, shuffle = False, num_workers = 8, pin_memory=True)\n",
    "test_future_loader = torch.utils.data.DataLoader(test_future_set, batch_size = batch_size, shuffle = False, num_workers = 8, pin_memory=True)\n",
    "test_domain_loader = torch.utils.data.DataLoader(test_domain_set, batch_size = batch_size, shuffle = False, num_workers = 8, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBC_modelResNet_Mag_bz3_inp24_pred3_lr0.001_decay0.95_kernel3_seed0\n"
     ]
    }
   ],
   "source": [
    "save_name = args.dataset + \"_model{}_bz{}_inp{}_pred{}_lr{}_decay{}_kernel{}_seed{}\".format(model_name,\n",
    "                                                                                                batch_size,\n",
    "                                                                                                input_length,\n",
    "                                                                                                train_output_length,\n",
    "                                                                                                learning_rate,\n",
    "                                                                                                lr_decay,\n",
    "                                                                                                kernel_size, \n",
    "                                                                                                args.seed)\n",
    "                                                                                        \n",
    "print(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"ResNet_UM\":\n",
    "    model = ResNet_UM(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "elif model_name == \"Unet_UM\":\n",
    "    model = Unet_UM(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "elif model_name == \"ResNet_Rot\":\n",
    "    model = ResNet_Rot(input_frames = input_length, output_frames = 1, kernel_size = kernel_size, N = 8).to(device)\n",
    "elif model_name == \"Unet_Rot\":\n",
    "    model = Unet_Rot(input_frames = input_length, output_frames = 1, kernel_size = kernel_size, N = 8).to(device)\n",
    "elif model_name == \"ResNet_Mag\":\n",
    "    model = ResNet_Mag(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "elif model_name == \"Unet_Mag\":  \n",
    "    model = Unet_Mag(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "elif model_name == \"ResNet_Scale\":\n",
    "    model = ResNet_Scale(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "elif model_name == \"Unet_Scale\":  \n",
    "    model = Unet_Scale(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "elif model_name == \"ResNet_None\":\n",
    "    model = ResNet(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "elif model_name == \"Unet_None\":\n",
    "    model = Unet(input_channels = input_length*2, output_channels = 2, kernel_size = kernel_size).to(device)\n",
    "else:\n",
    "    print(\"Invalid model name entered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate,betas=(0.9, 0.999), weight_decay=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=lr_decay)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_rmse = 1e6\n",
    "# train_rmse = []\n",
    "# valid_rmse = []\n",
    "# test_rmse = []\n",
    "\n",
    "# for i in tqdm(range(num_epoch), desc = 'Training'):\n",
    "#     start = time.time()\n",
    "    \n",
    "#     if symmetry != \"Scale\":\n",
    "#         model.train()\n",
    "#         train_rmse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "#         model.eval()\n",
    "#         rmse, _, _ = eval_epoch(valid_loader, model, loss_fun)\n",
    "#         valid_rmse.append(rmse)\n",
    "#     else:\n",
    "#         model.train()\n",
    "#         train_rmse.append(train_epoch_scale(train_loader, model, optimizer, loss_fun))\n",
    "#         model.eval()\n",
    "#         rmse, _, _ = eval_epoch_scale(valid_loader, model, loss_fun)\n",
    "#         valid_rmse.append(rmse)\n",
    "\n",
    "#     if valid_rmse[-1] < min_rmse:\n",
    "#         min_rmse = valid_rmse[-1] \n",
    "#         best_model = model\n",
    "#     end = time.time()\n",
    "    \n",
    "#     # Early Stopping but train at least for 50 epochs\n",
    "#     if (len(train_rmse) > 50 and np.mean(valid_rmse[-5:]) >= np.mean(valid_rmse[-10:-5])):\n",
    "#             break\n",
    "#     print(\"Epoch {} | T: {:0.2f} | Train RMSE: {:0.3f} | Valid RMSE: {:0.3f}\".format(i + 1, (end-start) / 60, train_rmse[-1], valid_rmse[-1]))\n",
    "#     scheduler.step()\n",
    "    \n",
    "    \n",
    "# if symmetry != \"Scale\":\n",
    "#     test_future_rmse, test_future_preds, test_future_trues, test_future_loss_curve = test_epoch(test_future_loader, best_model, loss_fun)\n",
    "#     test_domain_rmse, test_domain_preds, test_domain_trues, test_domain_loss_curve = test_epoch(test_domain_loader, best_model, loss_fun)\n",
    "# else:\n",
    "#     test_future_rmse, test_future_preds, test_future_trues, test_future_loss_curve = test_epoch_scale(test_future_loader, best_model, loss_fun)\n",
    "#     test_domain_rmse, test_domain_preds, test_domain_trues, test_domain_loss_curve = test_epoch_scale(test_domain_loader, best_model, loss_fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 48, 64, 64]), torch.Size([3, 3, 2, 64, 64]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_mult(x):\n",
    "    shape = x.shape\n",
    "    batch_size = shape[0]\n",
    "    lens = np.ones(len(shape)-1)\n",
    "    lens = lens.astype(int)\n",
    "    lens = np.append(batch_size, lens)\n",
    "    mult = torch.rand(*lens)\n",
    "    return x * mult\n",
    "\n",
    "mult = torch.rand(batch_size)\n",
    "def mag_mult(x):\n",
    "    shape = x.shape\n",
    "    batch_size = shape[0]\n",
    "    lens = np.ones(len(shape)-1)\n",
    "    lens = lens.astype(int)\n",
    "    lens = np.append(batch_size, lens)\n",
    "    mult2 = mult.view(*lens)\n",
    "    return x * mult2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = input_length*2\n",
    "output_channels = 32\n",
    "kernel_size = kernel_size\n",
    "um_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "resblock_none\n",
      "Equivariance test failed. \n",
      "Max difference:  2.74568 \n",
      "Mean difference: 0.212647\n",
      "\n",
      "non_conv\n",
      "Equivariance test failed. \n",
      "Max difference:  0.0326888 \n",
      "Mean difference: 0.0121383\n",
      "\n",
      "\n",
      "residual upscale add\n",
      "residual upscale add\n",
      "in torch.Size([3, 32, 64, 64])\n",
      "stds torch.Size([3, 1, 64, 64])\n",
      "in torch.Size([3, 32, 64, 64])\n",
      "stds torch.Size([3, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "mag_conv = mag_conv2d(\n",
    "    input_channels = input_length*2,\n",
    "    output_channels = 32,\n",
    "    kernel_size = kernel_size,\n",
    "    um_dim = 2,\n",
    ")\n",
    "\n",
    "non_conv = nn.Conv2d(\n",
    "    in_channels = input_length*2,\n",
    "    out_channels = 32,\n",
    "    kernel_size = kernel_size,\n",
    "    padding = (kernel_size - 1)//2,\n",
    ")\n",
    "\n",
    "out = mag_conv(x)\n",
    "\n",
    "my_mag_conv = Conv2dMag(\n",
    "    input_channels = input_length*2,\n",
    "    output_channels = 32,\n",
    "    kernel_size = kernel_size,\n",
    ")\n",
    "\n",
    "\n",
    "# unfolded = conv.unfold(x)\n",
    "# # print(out.shape)\n",
    "\n",
    "# transformed, stds = conv.transform(unfolded)\n",
    "# # print(transformed.shape, stds.shape)\n",
    "\n",
    "# conved = conv.conv2d(transformed)\n",
    "# # print(conved.shape)\n",
    "\n",
    "# inverse_transformed = conv.inverse_transform(conved, stds)\n",
    "\n",
    "print_only = False\n",
    "atol = 1e-5\n",
    "\n",
    "resblock_mag  = mag_resblock(input_channels, 64, kernel_size)\n",
    "resblock_none = Resblock(input_channels, 64, kernel_size)\n",
    "\n",
    "print('\\nresblock_none')\n",
    "assert_equiv(x, mag_mult, resblock_none, atol=atol, print_only=True)\n",
    "print('\\nnon_conv')\n",
    "assert_equiv(x, mag_mult, non_conv, atol=atol, print_only=True)\n",
    "\n",
    "print('\\n')\n",
    "assert_equiv(x, mag_mult, resblock_mag, atol=atol, print_only=print_only)\n",
    "assert_equiv(x, mag_mult, mag_conv, atol=atol, print_only=print_only)\n",
    "assert_equiv(x, mag_mult, my_mag_conv, atol=atol, print_only=print_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual upscale add\n",
      "torch.Size([3, 64, 64, 64]) tensor(0.2598, grad_fn=<MeanBackward0>)\n",
      "torch.Size([3, 48, 64, 64]) tensor(-0.1797)\n",
      "torch.Size([3, 64, 64, 64]) tensor(0.1444, grad_fn=<MeanBackward0>)\n",
      "residual upscale add\n",
      "torch.Size([3, 64, 64, 64]) tensor(0.1262, grad_fn=<MeanBackward0>)\n",
      "torch.Size([3, 48, 64, 64]) tensor(-0.0794)\n",
      "torch.Size([3, 64, 64, 64]) tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "Equivariance test passed.\n"
     ]
    }
   ],
   "source": [
    "resblock_mag  = mag_resblock(input_channels, 64, kernel_size)\n",
    "\n",
    "assert_equiv(x, mag_mult, resblock_mag, atol=atol, print_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in torch.Size([3, 32, 64, 64])\n",
      "stds torch.Size([3, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "my_mag_conv2 = my_mag_conv2d(\n",
    "    input_channels = input_length*2,\n",
    "    output_channels = 32,\n",
    "    kernel_size = kernel_size,\n",
    ")\n",
    "\n",
    "out = my_mag_conv2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35, 15])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx, nt = 10, 15\n",
    "\n",
    "u = torch.rand(1, nx, nt)\n",
    "dx = torch.rand(1, nx, nt)\n",
    "dt = torch.rand(1, nt, nt)\n",
    "\n",
    "cat = torch.cat([u, dx, dt], dim=1)\n",
    "cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mag_conv1 = Conv1dMag(\n",
    "    input_channels = input_length*2,\n",
    "    output_channels = 32,\n",
    "    kernel_size = kernel_size,\n",
    ")\n",
    "\n",
    "x1d = x[..., 0]\n",
    "out = my_mag_conv1(x1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x1d, 'x1d.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 48, 64])\n",
      "tensor(-0.4090) tensor(0.9056)\n",
      "Equivariance test passed.\n",
      "tensor(0.1278, grad_fn=<MeanBackward0>) tensor(0.1278, grad_fn=<MeanBackward0>) tensor(0.1762, grad_fn=<StdBackward0>) tensor(0.1762, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x1d.shape)\n",
    "print(x1d.mean(), x1d.std())\n",
    "y1, y2 = assert_equiv(x1d, mag_mult, my_mag_conv1, atol=1e-6, print_only=True)\n",
    "print(y1.mean(), y2.mean(), y1.std(), y2.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in torch.Size([3, 48, 64, 64])\n",
      "padded torch.Size([3, 48, 66, 66])\n",
      "unfold torch.Size([3, 432, 4096])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m my_conv \u001b[38;5;241m=\u001b[39m my_mag_conv2d(\n\u001b[1;32m      2\u001b[0m     input_channels \u001b[38;5;241m=\u001b[39m input_length\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      3\u001b[0m     output_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      4\u001b[0m     kernel_size \u001b[38;5;241m=\u001b[39m kernel_size,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m my_out \u001b[38;5;241m=\u001b[39m my_conv(x)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[43mmy_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m)\u001b[38;5;241m.\u001b[39mall(), torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(my_out \u001b[38;5;241m-\u001b[39m out))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "my_conv = my_mag_conv2d(\n",
    "    input_channels = input_length*2,\n",
    "    output_channels = 32,\n",
    "    kernel_size = kernel_size,\n",
    ")\n",
    "\n",
    "my_out = my_conv(x)\n",
    "assert (my_out == out).all(), torch.mean(torch.abs(my_out - out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 2, 3, 3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2, 3, 64, 64])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped = unfolded.reshape(3, 24, 2, 3, 3, 64, 64)\n",
    "print(reshaped.shape)\n",
    "reshaped.max(1).values.unsqueeze(1).max(3).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 48, 64, 64])\n",
      "torch.Size([3, 48, 3, 3, 64, 64])\n",
      "torch.Size([3, 48, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "(torch.Size([3, 64, 64, 64]), torch.Size([3, 48, 64, 64]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sympde/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sympde/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documenten MBA/Studie/Thesis/SymPDE/ext_repos/Equivariant-Net/models/model_mag.py:99\u001b[0m, in \u001b[0;36mmag_conv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2d(x)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m x_org\u001b[38;5;241m.\u001b[39mshape), (out\u001b[38;5;241m.\u001b[39mshape, x_org\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation:\n\u001b[1;32m    101\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "\u001b[0;31mAssertionError\u001b[0m: (torch.Size([3, 64, 64, 64]), torch.Size([3, 48, 64, 64]))"
     ]
    }
   ],
   "source": [
    "conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = out.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out == out2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 3, 3, 64, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([3, 48, 64, 64])\n",
      "torch.Size([3, 48, 64, 64])\n",
      "torch.Size([3, 48, 3, 3, 64, 64])\n",
      "torch.Size([3, 48, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "activation torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 3, 3, 64, 64])\n",
      "torch.Size([3, 64, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "activation torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 48, 64, 64])\n",
      "torch.Size([3, 48, 3, 3, 64, 64])\n",
      "torch.Size([3, 48, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "forward torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 3, 3, 64, 64])\n",
      "torch.Size([3, 64, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "activation torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 3, 3, 64, 64])\n",
      "torch.Size([3, 64, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "activation torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "forward torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 3, 3, 64, 64])\n",
      "torch.Size([3, 64, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "activation torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 3, 3, 64, 64])\n",
      "torch.Size([3, 128, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "activation torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 64, 64, 64])\n",
      "torch.Size([3, 64, 3, 3, 64, 64])\n",
      "torch.Size([3, 64, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "forward torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 3, 3, 64, 64])\n",
      "torch.Size([3, 128, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "activation torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 3, 3, 64, 64])\n",
      "torch.Size([3, 128, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "activation torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "forward torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 3, 3, 64, 64])\n",
      "torch.Size([3, 128, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "activation torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 3, 3, 64, 64])\n",
      "torch.Size([3, 256, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "activation torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 128, 64, 64])\n",
      "torch.Size([3, 128, 3, 3, 64, 64])\n",
      "torch.Size([3, 128, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "forward torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 3, 3, 64, 64])\n",
      "torch.Size([3, 256, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "activation torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 3, 3, 64, 64])\n",
      "torch.Size([3, 256, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "activation torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "forward torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 3, 3, 64, 64])\n",
      "torch.Size([3, 256, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "activation torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 3, 3, 64, 64])\n",
      "torch.Size([3, 512, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "activation torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 256, 64, 64])\n",
      "torch.Size([3, 256, 3, 3, 64, 64])\n",
      "torch.Size([3, 256, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "forward torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 3, 3, 64, 64])\n",
      "torch.Size([3, 512, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "activation torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 3, 3, 64, 64])\n",
      "torch.Size([3, 512, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "activation torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "forward torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 64, 64])\n",
      "torch.Size([3, 512, 3, 3, 64, 64])\n",
      "torch.Size([3, 512, 192, 192]) torch.Size([3, 1, 2, 64, 64])\n",
      "torch.Size([3, 2, 64, 64])\n",
      "torch.Size([3, 2, 64, 64])\n",
      "out torch.Size([3, 2, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.6323e-02, -5.0285e-02, -4.9234e-02,  ..., -5.5318e-02,\n",
       "           -5.7749e-02, -6.2793e-02],\n",
       "          [-6.7118e-02, -6.6979e-02, -7.2402e-02,  ..., -4.1469e-02,\n",
       "           -4.2685e-02, -4.7675e-02],\n",
       "          [-7.7572e-02, -7.4063e-02, -8.0540e-02,  ..., -1.3340e-02,\n",
       "           -1.6663e-02, -2.1257e-02],\n",
       "          ...,\n",
       "          [-5.6505e-02, -5.4493e-02, -5.4724e-02,  ..., -1.1731e-02,\n",
       "           -1.7330e-02, -2.3117e-02],\n",
       "          [-5.3550e-02, -5.2407e-02, -5.6243e-02,  ..., -1.9907e-03,\n",
       "            2.6783e-03, -4.3141e-04],\n",
       "          [-4.6165e-02, -4.5276e-02, -4.9311e-02,  ..., -5.3422e-02,\n",
       "           -4.7472e-02, -4.9616e-02]],\n",
       "\n",
       "         [[-2.4309e-03, -6.7737e-04,  8.8923e-03,  ...,  4.9826e-02,\n",
       "            5.5412e-02,  5.7955e-02],\n",
       "          [-1.4533e-02, -1.2620e-02, -1.1789e-02,  ...,  3.3725e-02,\n",
       "            3.5838e-02,  3.8212e-02],\n",
       "          [-4.8281e-02, -5.2890e-02, -5.5887e-02,  ...,  5.0041e-02,\n",
       "            5.0288e-02,  4.8916e-02],\n",
       "          ...,\n",
       "          [ 1.1685e-01,  1.3592e-01,  1.6103e-01,  ...,  1.6055e-02,\n",
       "            1.1517e-02,  9.2612e-03],\n",
       "          [ 1.1408e-01,  1.2797e-01,  1.4238e-01,  ...,  1.2576e-02,\n",
       "            1.3386e-02,  1.9126e-02],\n",
       "          [ 1.0054e-01,  1.1087e-01,  1.1841e-01,  ..., -9.4948e-03,\n",
       "           -1.4321e-02, -6.3663e-03]]],\n",
       "\n",
       "\n",
       "        [[[-6.3352e-02, -6.8409e-02, -6.7717e-02,  ..., -4.4295e-02,\n",
       "           -3.2382e-02, -3.2098e-02],\n",
       "          [-7.0238e-02, -7.3429e-02, -6.9959e-02,  ..., -4.6930e-02,\n",
       "           -2.8107e-02, -2.0961e-02],\n",
       "          [-7.6461e-02, -7.9031e-02, -7.7418e-02,  ..., -3.5133e-02,\n",
       "           -1.3984e-02, -7.9415e-03],\n",
       "          ...,\n",
       "          [-4.1688e-02, -4.6710e-02, -4.0998e-02,  ..., -9.9906e-02,\n",
       "           -1.0260e-01, -1.0279e-01],\n",
       "          [-3.2967e-02, -4.0868e-02, -3.4836e-02,  ..., -7.6646e-02,\n",
       "           -8.1690e-02, -8.2176e-02],\n",
       "          [-1.3700e-02, -2.1878e-02, -2.2812e-02,  ..., -6.9803e-02,\n",
       "           -7.4395e-02, -7.6059e-02]],\n",
       "\n",
       "         [[ 5.4272e-03,  3.4183e-03,  1.2625e-03,  ...,  5.5807e-03,\n",
       "            5.5676e-03,  4.0438e-03],\n",
       "          [ 1.1874e-02,  1.0896e-02,  9.0016e-03,  ...,  1.1267e-02,\n",
       "            1.0223e-02,  5.1675e-03],\n",
       "          [ 2.6314e-02,  2.4831e-02,  2.3359e-02,  ...,  4.3085e-03,\n",
       "            7.1176e-04, -1.8502e-03],\n",
       "          ...,\n",
       "          [ 1.8133e-02,  2.5643e-02,  2.8830e-02,  ...,  2.1703e-02,\n",
       "            2.4222e-02,  2.5663e-02],\n",
       "          [ 1.7889e-02,  2.4583e-02,  3.2980e-02,  ...,  1.8378e-02,\n",
       "            1.9658e-02,  2.2255e-02],\n",
       "          [ 3.0368e-02,  3.7935e-02,  4.4226e-02,  ...,  1.3741e-02,\n",
       "            1.5530e-02,  1.7625e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.2548e-02, -4.0188e-02, -3.7443e-02,  ..., -3.2943e-02,\n",
       "           -2.9538e-02, -3.0030e-02],\n",
       "          [-2.3593e-02, -3.0097e-02, -2.4802e-02,  ..., -2.5658e-02,\n",
       "           -2.0855e-02, -2.2609e-02],\n",
       "          [-2.7695e-02, -3.4059e-02, -2.7107e-02,  ..., -2.7218e-02,\n",
       "           -1.9079e-02, -1.7234e-02],\n",
       "          ...,\n",
       "          [-3.6583e-02, -3.4698e-02, -3.0215e-02,  ..., -1.4917e-02,\n",
       "           -2.1697e-02, -2.8781e-02],\n",
       "          [-1.5242e-02, -1.5588e-02, -1.4957e-02,  ..., -1.5484e-02,\n",
       "           -2.5944e-02, -3.5249e-02],\n",
       "          [-1.5529e-02, -1.7425e-02, -1.5779e-02,  ..., -2.2363e-02,\n",
       "           -2.3324e-02, -3.1263e-02]],\n",
       "\n",
       "         [[ 2.4120e-02,  2.4665e-02,  1.1792e-02,  ...,  3.6487e-02,\n",
       "            3.6517e-02,  3.5059e-02],\n",
       "          [ 1.2275e-02,  1.1648e-02,  1.2703e-04,  ...,  5.3162e-02,\n",
       "            5.6044e-02,  5.5636e-02],\n",
       "          [ 1.3630e-02,  7.5629e-03, -1.5693e-02,  ...,  8.8305e-02,\n",
       "            9.0808e-02,  9.2325e-02],\n",
       "          ...,\n",
       "          [ 3.2959e-02,  3.5193e-02,  4.3965e-02,  ...,  9.9277e-04,\n",
       "           -8.9007e-03, -1.2001e-02],\n",
       "          [ 2.2565e-02,  2.3796e-02,  2.9017e-02,  ...,  1.6376e-03,\n",
       "           -1.2744e-02, -1.2426e-02],\n",
       "          [ 1.6803e-02,  1.5816e-02,  2.0181e-02,  ..., -3.0811e-07,\n",
       "           -9.9200e-03, -1.1724e-02]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes in ResNet_rot\n",
    "# for i in [16, 32, 64, 128, 192]:\n",
    "#     print(i, i*8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sympde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
