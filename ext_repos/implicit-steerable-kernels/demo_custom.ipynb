{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from escnn import nn, group, gspaces\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.core.point_convolution import ImplicitPointConv\n",
    "from utils.utils import get_elu\n",
    "from models.core.implicit_kernel import ImplicitKernelSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azymuthal-rotation equivariant model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a convolutional layer that is equivariant under rotations around the z-axis and acts on field on $\\mathbb{R}^3$.\n",
    "\n",
    "Since we work in escnn, we need to specify the group space, and indicate which subgroup of O(3) we work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspace = gspaces.rot2dOnR3() # SO(2) on R^3\n",
    "subgroup_id = gspace._sg_id[:-1] # indicator for the subgroup SO(2) \\in O(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that our input is 3 vector fields and 2 scalar fields, and the output is 1 vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict the standard representation of O(3) to SO(2)\n",
    "std_repr = group.o3_group().standard_representation().restrict(subgroup_id) \n",
    "triv_repr = gspace.trivial_repr \n",
    "\n",
    "in_repr = 3*[std_repr] + 2*[triv_repr]\n",
    "out_repr = 1*[std_repr] + 1*[triv_repr]\n",
    "\n",
    "# set field type of the input and output\n",
    "in_type = gspace.type(*in_repr)\n",
    "out_type = gspace.type(*out_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implicit point convolution takes as input node and edge features of a geometric graph.\n",
    "\n",
    "Hence, we have to specify the representation of edge features.\n",
    "\n",
    "Let us assume that we have 2 edge features,  one of which is a scalar field and one is a vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_repr = 1*[gspaces.no_base_space(group.o3_group()).trivial_repr] + 1*[group.o3_group().standard_representation()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OPTIONAL] For better initialization, we can give an approximate feature distribution to the kernel.\n",
    "\n",
    "First element is for relative positions, second is for additional edge features specified above.\n",
    "\n",
    "Assuming that edge features follow a normal distribution with mean 0 and std 0.5, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_distr = [None, torch.distributions.Normal(torch.zeros(4), 0.5*torch.ones(4))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to specify the order of harmonic polynomials we use in the implicit kernel.\n",
    "\n",
    "Let's use polynomials of order 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_order = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now build a Steerable CNN model with 3 convolutional layers and QuotientFourier non-linearity.\n",
    "\n",
    "It is important to say that implicit kernels only support uniform representations.\n",
    "\n",
    "It means that the input and output representations of the model must be the copies of the same representation.\n",
    "\n",
    "This is not a limitatiom per se, since we can always map a non-uniform representation to a uniform one, e.g. using a Projector module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we need to specify parameters of the MLP with which we parametrize steerable filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = dict(n_layers=3, \n",
    "                  n_channels=8, \n",
    "                  act_fn='elu', \n",
    "                  use_tp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(nn.EquivariantModule):\n",
    "    def __init__(self, in_type: nn.FieldType, out_type: nn.FieldType):\n",
    "        super().__init__()\n",
    "        G = in_type.gspace.fibergroup\n",
    "        gspace = gspaces.no_base_space(G)\n",
    "        self.in_type = in_type\n",
    "        self.hid_type1 = gspace.type(*in_type.representations)\n",
    "        self.hid_type2 = gspace.type(*out_type.representations)\n",
    "        self.linear = nn.Linear(self.hid_type1, self.hid_type2) \n",
    "        self.out_type = out_type\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, coords = x.tensor, x.coords\n",
    "        x = self.hid_type1(x)\n",
    "        x = self.linear(x)\n",
    "        x = nn.GeometricTensor(x.tensor, self.out_type, coords)\n",
    "        return x\n",
    "    \n",
    "    def evaluate_output_shape(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hidden fields with representation: SO(2)|[regular_[(0,)|(1,)]]:3\n"
     ]
    }
   ],
   "source": [
    "# We use 16 hidden channels for all layers and band-limit representations up to frequency L=1\n",
    "hidden_channels = 3\n",
    "L = 1\n",
    "\n",
    "activation = get_elu(gspace = in_type.gspace, L = L, channels = hidden_channels)\n",
    "\n",
    "# in Steerable CNNs, hidden channels are determined by the activation function.\n",
    "hidden_type = activation.out_type\n",
    "# print(f\"hidden type: {hidden_type} with size {hidden_type.size}\\nL = {L}, hidden channels = {hidden_channels}\")\n",
    "print(f\"{hidden_channels} hidden fields with representation: {hidden_type.representations[0]}\")\n",
    "\n",
    "proj_in = Projector(in_type, hidden_type)\n",
    "\n",
    "layer1 = ImplicitPointConv(\n",
    "    in_type=hidden_type,\n",
    "    out_type=hidden_type,\n",
    "    edge_repr=edge_repr,\n",
    "    hp_order=hp_order,\n",
    "    edge_distr=edge_distr,\n",
    "    **mlp_params)\n",
    "\n",
    "x = x_org = nn.GeometricTensor(torch.randn(10,hidden_type.size), layer1.in_type, torch.randn(10,3))\n",
    "\n",
    "edge_index = torch.randint(0, 10, (2, 20))\n",
    "edge_delta = torch.randn(20,3)\n",
    "edge_attr = torch.randn(20,4)\n",
    "\n",
    "outa_orgimpl = layer1(x=x, edge_index=edge_index, edge_delta=edge_delta, edge_attr=edge_attr, idx_downsampled=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test equivariance\n",
    "\n",
    "We need to specify the type of edge features for the layer (it is done automatically inside the implicit kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_type = gspaces.no_base_space(group.o3_group()).type(*[group.o3_group().standard_representation()]).restrict(subgroup_id) \n",
    "edge_type = gspaces.no_base_space(group.o3_group()).type(*edge_repr).restrict(subgroup_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_org = nn.GeometricTensor(torch.randn(10,hidden_type.size), layer1.in_type, torch.randn(10,3))\n",
    "\n",
    "edge_index = torch.randint(0, 10, (2, 20))\n",
    "edge_delta = torch.randn(20,3)\n",
    "edge_attr = torch.randn(20,4)\n",
    "\n",
    "\n",
    "el = list(gspace.testing_elements)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(src, index, dim_size, dim):\n",
    "    \"\"\"\n",
    "    From \n",
    "    - /Users/elias/anaconda3/envs/sympde/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py\n",
    "    - /Users/elias/anaconda3/envs/sympde/lib/python3.10/site-packages/torch_geometric/nn/resolver.py\n",
    "    - /Users/elias/anaconda3/envs/sympde/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py\n",
    "    - /Users/elias/anaconda3/envs/sympde/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py\n",
    "    - /Users/elias/anaconda3/envs/sympde/lib/python3.10/site-packages/torch_geometric/utils/scatter.py\n",
    "    \"\"\"\n",
    "\n",
    "    def broadcast(src, ref, dim: int):\n",
    "        size = ((1, ) * dim) + (-1, ) + ((1, ) * (ref.dim() - dim - 1))\n",
    "        return src.view(size).expand_as(ref)\n",
    "    \n",
    "    size = src.size()[:dim] + (dim_size, ) + src.size()[dim + 1:]\n",
    "\n",
    "    count = src.new_zeros(dim_size)\n",
    "    count.scatter_add_(0, index, src.new_ones(src.size(dim)))\n",
    "    count = count.clamp(min=1)\n",
    "\n",
    "    index = broadcast(index, src, dim)\n",
    "    out = src.new_zeros(size).scatter_add_(dim, index, src)\n",
    "\n",
    "    out = out / broadcast(count, out, dim)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_repr, out_repr = hidden_type, hidden_type\n",
    "\n",
    "k = implicit_kernel = ImplicitKernelSON(\n",
    "    in_repr=in_repr, \n",
    "    out_repr=out_repr,\n",
    "    edge_repr=edge_repr, \n",
    "    hp_order=hp_order,\n",
    "    **mlp_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3, 'n_channels': 8, 'act_fn': 'elu', 'use_tp': False}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 2.02e-03, mean 1.96e-04, std 3.06e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Tranform a\n",
    "x_a = x_org\n",
    "\n",
    "\n",
    "\n",
    "x = k.transform_coords(edge_delta)\n",
    "x = nn.GeometricTensor(torch.cat([x.tensor, edge_attr], 1), k.mlp.in_type)\n",
    "x = k.mlp(x)\n",
    "x = k.transform_mlp(x, edge_delta, init=True)\n",
    "c_in, c_out  = len(in_repr), len(out_repr)\n",
    "delta_in, delta_out = int(in_repr.size / len(in_repr)), int(out_repr.size / len(out_repr))\n",
    "filter = x.reshape((-1, c_out * delta_out, c_in * delta_in)) # shape: [n_edges, c_out, c_in]\n",
    "\n",
    "x_j = torch.stack([x_a.tensor[i] for i in edge_index[0]]) # shape: [n_edges, c_in]\n",
    "outa_einsum = torch.einsum('noi,ni->no', filter, x_j) # shape: [2*n_edges, c_out]\n",
    "outa = aggregate(src=outa_einsum, index=edge_index[1], dim_size=10, dim=0) # shape: [n_edges, c_out]\n",
    "\n",
    "outa = nn.GeometricTensor(outa, type = hidden_type, coords=x_a.coords) \n",
    "\n",
    "outa = outa.transform_fibers(el)\n",
    "outa = outa.tensor.detach()\n",
    "\n",
    "\n",
    "\n",
    "### Tranform b\n",
    "x_b = x_transformed = x_org.transform_fibers(el)\n",
    "edge_delta_transformed = nn.GeometricTensor(edge_delta, std_type).transform_fibers(el).tensor\n",
    "edge_attr_transformed = nn.GeometricTensor(edge_attr, edge_type).transform_fibers(el).tensor\n",
    "\n",
    "x = k.transform_coords(edge_delta_transformed)\n",
    "x0 = x = nn.GeometricTensor(torch.cat([x.tensor, edge_attr_transformed], 1), k.mlp.in_type)\n",
    "x1 = x = k.mlp(x)\n",
    "x_tranf = x = k.transform_mlp(x, edge_delta_transformed, init=True)\n",
    "filter_tranformed = x.reshape((-1, c_out * delta_out, c_in * delta_in)) # shape: [n_edges, c_out, c_in]\n",
    "\n",
    "x_j = torch.stack([x_b.tensor[i] for i in edge_index[0]]) # shape: [n_edges, c_in]\n",
    "outb_einsum = torch.einsum('noi,ni->no', filter_tranformed, x_j) # shape: [2*n_edges, c_out]\n",
    "outb = aggregate(src=outb_einsum, index=edge_index[1], dim_size=10, dim=0) # shape: [n_edges, c_out]\n",
    "\n",
    "outb = nn.GeometricTensor(outb, type = hidden_type, coords=x_b.coords)\n",
    "outb = outb.tensor.detach().numpy()\n",
    "\n",
    "diff = np.abs(outa - outb)\n",
    "\n",
    "print(f\"max {diff.max():.2e}, mean {diff.mean():.2e}, std {diff.std():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots = [filter_tranformed[0].detach().numpy(), filter[0].detach().numpy()]\n",
    "\n",
    "n_plots = len(plots)\n",
    "fig, axs = plt.subplots(1,n_plots, figsize = (3*n_plots,5))\n",
    "for ax, p in zip(axs, plots):\n",
    "    im = ax.imshow(p)\n",
    "    fig.colorbar(im, ax=ax, shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 13]),\n",
       " torch.Size([20, 81]),\n",
       " torch.Size([20, 3, 3, 3, 3]),\n",
       " torch.Size([20, 9, 9]),\n",
       " torch.Size([20, 9]),\n",
       " (10, 9))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape, x1.shape, x_tranf.shape, filter_tranformed.shape, outb_einsum.shape, outb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 3]),\n",
       " torch.Size([20, 4]),\n",
       " torch.Size([20, 9, 9]),\n",
       " torch.Size([20, 9]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_delta.shape, edge_attr.shape, filter_tranformed.shape, outb_einsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 1.83e-03, mean 2.42e-04, std 3.26e-04\n"
     ]
    }
   ],
   "source": [
    "x = x_org\n",
    "\n",
    "outa_orgimpl = layer1(x=x, edge_index=edge_index, edge_delta=edge_delta, edge_attr=edge_attr, idx_downsampled=None).transform_fibers(el).tensor.detach().numpy()\n",
    "\n",
    "edge_delta_ = nn.GeometricTensor(edge_delta, std_type)\n",
    "edge_attr_ = nn.GeometricTensor(edge_attr, edge_type)\n",
    "outb_orgimpl = layer1(x.transform_fibers(el), \n",
    "                edge_index=edge_index, \n",
    "                edge_delta=edge_delta_.transform_fibers(el).tensor, \n",
    "                edge_attr=edge_attr_.transform_fibers(el).tensor, \n",
    "                idx_downsampled=None).tensor.detach().numpy()\n",
    "\n",
    "diff = np.abs(outa_orgimpl - outb_orgimpl)\n",
    "\n",
    "print(f\"max {diff.max():.2e}, mean {diff.mean():.2e}, std {diff.std():.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare x_j and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = torch.stack([x_org.tensor[i] for i in edge_index[0]])\n",
    "assert (x_j == torch.load(\"x_j.pt\")).all()\n",
    "x_j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = torch.cat(x)\n",
    "x_cat.shape, outa0.shape, edge_index[1].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# self.reduce(src = x = outa0, index = edge_index[1], ptr=None, dim_size = 10, dim = -2, reduce = 'mean')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast(src, ref, dim: int):\n",
    "    size = ((1, ) * dim) + (-1, ) + ((1, ) * (ref.dim() - dim - 1))\n",
    "    return src.view(size).expand_as(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = outa0\n",
    "index = edge_index[1]\n",
    "dim_size = 10\n",
    "dim = 0 #-2\n",
    "\n",
    "size = src.size()[:dim] + (dim_size, ) + src.size()[dim + 1:]\n",
    "\n",
    "count = src.new_zeros(dim_size)\n",
    "count.scatter_add_(0, index, src.new_ones(src.size(dim)))\n",
    "count = count.clamp(min=1)\n",
    "\n",
    "index = broadcast(index, src, dim)\n",
    "out = src.new_zeros(size).scatter_add_(dim, index, src)\n",
    "\n",
    "outa0 = out / broadcast(count, out, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outa02 = np.zeros_like(outa)\n",
    "\n",
    "for i in edge_index[1]:\n",
    "    sel_idxs = torch.where(edge_index[1] == i)\n",
    "    outa0_sels = outa0[sel_idxs]\n",
    "\n",
    "    # outa02[i] = torch.max(outa0[sel_idxs], axis = 0).values\n",
    "    outa02[i] += torch.mean(outa0[sel_idxs], axis = 0).numpy()\n",
    "\n",
    "\n",
    "\n",
    "# plots = [x_cat, x_j, x_j_recon]\n",
    "plots = [outa0, outa, outa02, x_agg]\n",
    "\n",
    "n_plots = len(plots)\n",
    "fig, axs = plt.subplots(1,n_plots, figsize = (3*n_plots,5))\n",
    "for ax, p in zip(axs, plots):\n",
    "    absmax = np.abs(p).max()\n",
    "    print(absmax)\n",
    "    ax.imshow(p, vmin = -absmax, vmax = absmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outa.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in plots:\n",
    "    print(p.min(), p.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outa02 = np.zeros_like(outa)\n",
    "\n",
    "for i, outa02_i in enumerate(outa02):\n",
    "    pass\n",
    "    # outa02_i[edge_index[0][i]] += outa[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outa02 = np.zeros_like(outa)\n",
    "\n",
    "for i in edge_index[1]:\n",
    "    # Sum\n",
    "    outa02[i] += outa0[i].detach().numpy()\n",
    "\n",
    "    # Mean\n",
    "    sel_idxs = torch.where(edge_index[1] == i)\n",
    "    outa02[i] = torch.mean(outa0[sel_idxs], axis = 0).detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outa0.shape, x_j.shape, edge_index.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sympde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
