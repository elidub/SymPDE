{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd())\n",
    "# sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "from common.utils import HDF5Dataset, DataCreator\n",
    "from experiments.models_cnn import CNN, ResNet, BasicBlock1d\n",
    "from experiments.models_fno import FNO1d\n",
    "from experiments.train_helper import *\n",
    "from equations.PDEs import PDE, KdV, KS, Heat\n",
    "from common.augmentation import Subalgebra\n",
    "from experiments.train import parse_options as lpsda_parse_options, main as lpsda_main\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../sympde'))\n",
    "from data.dataset import PDEDataset, PDEDataModule\n",
    "from data.utils import d_to_LT\n",
    "\n",
    "from model.setup import setup_model\n",
    "from model.networks.fno import FNO1d\n",
    "from model.learner import Learner\n",
    "\n",
    "from viz.plot_pde_data import plot_1ds\n",
    "\n",
    "from run import parse_options, main\n",
    "\n",
    "from data.utils import d_to_coords\n",
    "from data.pde_data_aug import augment_pde1, augment_KdV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LPSDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloader shapes 1 1 1\n",
      "Training on dataset data/KdV_train_10_easy.h5\n",
      "models/FNO1d_KdV_samples10_augmentation0000_shiftfourier_future20_time11271052.pt\n",
      "Number of parameters: 10856084\n"
     ]
    }
   ],
   "source": [
    "args_lpsda = lpsda_parse_options(notebook = True)\n",
    "args_lpsda.train_samples=10\n",
    "args_lpsda.suffix = 'easy'\n",
    "args_lpsda.device = 'cpu'\n",
    "\n",
    "ret_lpsda = lpsda_main(args_lpsda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7238, 0.7124, 0.6985,  ..., 0.7437, 0.7393, 0.7327],\n",
       "         [0.7270, 0.7162, 0.7028,  ..., 0.7453, 0.7414, 0.7354],\n",
       "         [0.7301, 0.7198, 0.7069,  ..., 0.7468, 0.7434, 0.7380],\n",
       "         ...,\n",
       "         [0.2395, 0.2926, 0.3979,  ..., 0.3884, 0.2936, 0.2410],\n",
       "         [0.2354, 0.2943, 0.4054,  ..., 0.3718, 0.2799, 0.2316],\n",
       "         [0.2317, 0.2965, 0.4133,  ..., 0.3553, 0.2664, 0.2225]]),\n",
       " tensor(0.4624),\n",
       " tensor(0.1976))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHECK!\n",
    "ret_lpsda['train_dataset'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset': <common.utils.HDF5Dataset at 0x150c1755b910>, 'model': FNO1d}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_lpsda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SymPDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not augmenting KdV!\n"
     ]
    }
   ],
   "source": [
    "args = parse_options(notebook=True)\n",
    "args.pde_name = 'KdV'\n",
    "args.seed = 42\n",
    "args.version = f'lpsda_merge'\n",
    "args.train = True\n",
    "args.log_dir = '../logs'\n",
    "\n",
    "ret = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7238, 0.7124, 0.6985,  ..., 0.7437, 0.7393, 0.7327],\n",
       "         [0.7270, 0.7162, 0.7028,  ..., 0.7453, 0.7414, 0.7354],\n",
       "         [0.7301, 0.7198, 0.7069,  ..., 0.7468, 0.7434, 0.7380],\n",
       "         ...,\n",
       "         [0.2395, 0.2926, 0.3979,  ..., 0.3884, 0.2936, 0.2410],\n",
       "         [0.2354, 0.2943, 0.4054,  ..., 0.3718, 0.2799, 0.2316],\n",
       "         [0.2317, 0.2965, 0.4133,  ..., 0.3553, 0.2664, 0.2225]]),\n",
       " tensor(0.4624),\n",
       " tensor(0.1976))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHECK1\n",
    "ret['train_dataset'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "(u, dx, dt) = ret['train_dataset'][0]\n",
    "us = u.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (us, dx, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4624) 256\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/eliasd/thesis/SymPDE/ext_repos/LPSDA/train.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsnellius.surf.nl/home/eliasd/thesis/SymPDE/ext_repos/LPSDA/train.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ret[\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m](batch)\n",
      "File \u001b[0;32m~/.conda/envs/sympde/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/sympde/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home6/eliasd/thesis/SymPDE/sympde/model/learner.py:37\u001b[0m, in \u001b[0;36mLearner.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m y \u001b[39m=\u001b[39m us[:, :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_start:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_end] \n\u001b[1;32m     36\u001b[0m \u001b[39m# Pass the time history through the network\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x, dx, dt)\n\u001b[1;32m     39\u001b[0m \u001b[39m# [batch, space, time] -> [batch, time, space]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/sympde/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/sympde/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/home6/eliasd/thesis/SymPDE/sympde/model/networks/fno.py:128\u001b[0m, in \u001b[0;36mFNO1d.forward\u001b[0;34m(self, u, dx, dt)\u001b[0m\n\u001b[1;32m    126\u001b[0m nx \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \n\u001b[1;32m    127\u001b[0m \u001b[39mprint\u001b[39m(dx, nx)\n\u001b[0;32m--> 128\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((u, dx[:, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m]\u001b[39m.\u001b[39mto(u\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, nx, \u001b[39m1\u001b[39m),\n\u001b[1;32m    129\u001b[0m                dt[:, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, nx, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(u\u001b[39m.\u001b[39mdevice)), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    132\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc0(x)\n\u001b[1;32m    133\u001b[0m \u001b[39m# [b, x, c] -> [b, c, x]\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 0"
     ]
    }
   ],
   "source": [
    "ret['model'](batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 256])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNO1d"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# CHECK1\n",
    "for i in range(3):\n",
    "    r = ret['train_dataset']\n",
    "    r_lpsda = ret_lpsda['train_dataset']\n",
    "    print(r[0][i] == r_lpsda[0][i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sympde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
