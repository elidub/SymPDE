{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../symlie'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from symlie.misc.utils import NumpyUtils, Results, tensor_operation, numpy_operation, Args\n",
    "from symlie.misc.viz import plot2d\n",
    "from symlie.model.setup import find_id_for_P, load_P_pred\n",
    "from symlie.model.networks.linear import CalculatedP\n",
    "from symlie.misc.viz import plot2d\n",
    "from symlie.data.generate_2d import sine1d, sine2d, flower, mnist\n",
    "from symlie.data.generate_data import datasets\n",
    "from symlie.data.dataset import FlatDataset\n",
    "\n",
    "from symlie.misc.utils_results import plot_data, assert_unique, pivot, plot_pivot, add_df_map_new, assert_columns_same, get_and_check_Ps, plot_seeds_and_Ps, rename_net, stringify_dict\n",
    "from symlie.misc.wandb import update_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543, 48)\n",
      "Index(['lr', 'net', 'bias', 'name', 'seed', 'tags', 'test', 'A_low', 'n_val',\n",
      "       'train', 'y_low', 'A_high', 'config', 'device', 'logger', 'n_test',\n",
      "       'run_id', 'y_high', 'log_dir', 'n_train', 'predict', 'version',\n",
      "       'y_multi', 'data_dir', 'eps_mult', 'n_splits', 'criterion', 'do_return',\n",
      "       'earlystop', 'grid_size', 'noise_std', 'only_flip', 'batch_size',\n",
      "       'max_epochs', 'data_kwargs', 'num_workers', 'out_features',\n",
      "       'generate_data', 'model_summary', 'args_processed', 'do_return_model',\n",
      "       'n_hidden_layers', 'transform_kwargs', 'use_P_from_noise',\n",
      "       'persistent_workers', 'run_name', 'test_loss', 'n_classes'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>net</th>\n",
       "      <th>bias</th>\n",
       "      <th>name</th>\n",
       "      <th>seed</th>\n",
       "      <th>tags</th>\n",
       "      <th>test</th>\n",
       "      <th>A_low</th>\n",
       "      <th>n_val</th>\n",
       "      <th>train</th>\n",
       "      <th>...</th>\n",
       "      <th>model_summary</th>\n",
       "      <th>args_processed</th>\n",
       "      <th>do_return_model</th>\n",
       "      <th>n_hidden_layers</th>\n",
       "      <th>transform_kwargs</th>\n",
       "      <th>use_P_from_noise</th>\n",
       "      <th>persistent_workers</th>\n",
       "      <th>run_name</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>n_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>TrainP</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[new, noise]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'eps_mult': [0, 1, 1, 1], 'only_flip': False}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>dandy-donkey-1960</td>\n",
       "      <td>6.474450e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>TrainP</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[new, noise]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'eps_mult': [0, 1, 1, 1], 'only_flip': False}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>swept-lion-1959</td>\n",
       "      <td>3.812419e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>TrainP</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>[new, noise]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'eps_mult': [0, 1, 1, 1], 'only_flip': False}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>atomic-planet-1958</td>\n",
       "      <td>1.422213e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>TrainP</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>[new, noise]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'eps_mult': [0, 1, 1, 1], 'only_flip': False}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>royal-mountain-1957</td>\n",
       "      <td>3.862118e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>TrainP</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>[new, noise]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'eps_mult': [0, 1, 1, 1], 'only_flip': False}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>glamorous-snowflake-1955</td>\n",
       "      <td>1.425501e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr     net   bias  name  seed          tags  test A_low  n_val  train  \\\n",
       "0  0.010  TrainP  False  None     3  [new, noise]  True   NaN   1000   True   \n",
       "1  0.001  TrainP  False  None     3  [new, noise]  True   NaN   1000   True   \n",
       "2  0.100  TrainP  False  None     3  [new, noise]  True   NaN   1000   True   \n",
       "3  0.001  TrainP  False  None     2  [new, noise]  True   NaN   1000   True   \n",
       "4  0.100  TrainP  False  None     2  [new, noise]  True   NaN   1000   True   \n",
       "\n",
       "   ...  model_summary args_processed do_return_model n_hidden_layers  \\\n",
       "0  ...          False           True           False             1.0   \n",
       "1  ...          False           True           False             1.0   \n",
       "2  ...          False           True           False             1.0   \n",
       "3  ...          False           True           False             1.0   \n",
       "4  ...          False           True           False             1.0   \n",
       "\n",
       "                                 transform_kwargs  use_P_from_noise  \\\n",
       "0  {'eps_mult': [0, 1, 1, 1], 'only_flip': False}             False   \n",
       "1  {'eps_mult': [0, 1, 1, 1], 'only_flip': False}             False   \n",
       "2  {'eps_mult': [0, 1, 1, 1], 'only_flip': False}             False   \n",
       "3  {'eps_mult': [0, 1, 1, 1], 'only_flip': False}             False   \n",
       "4  {'eps_mult': [0, 1, 1, 1], 'only_flip': False}             False   \n",
       "\n",
       "  persistent_workers                  run_name     test_loss  n_classes  \n",
       "0               True         dandy-donkey-1960  6.474450e-05        NaN  \n",
       "1               True           swept-lion-1959  3.812419e-02        NaN  \n",
       "2               True        atomic-planet-1958  1.422213e-07        NaN  \n",
       "3               True       royal-mountain-1957  3.862118e-02        NaN  \n",
       "4               True  glamorous-snowflake-1955  1.425501e-07        NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update_results_df()\n",
    "\n",
    "df_map_columns = ['run_id', 'tags', 'data_kwargs', 'transform_kwargs', 'seed', 'data_dir']\n",
    "\n",
    "df = pd.read_pickle('../logs/store/results_df.pkl')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head()\n",
    "\n",
    "# df['tags'].astype(str).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams_min=('test_loss', 0.1)\n"
     ]
    }
   ],
   "source": [
    "group_params = ['eps_mult', 'noise_std']\n",
    "hyper_params  = ['lr']\n",
    "\n",
    "datasets_predict = [\n",
    "    'noise',\n",
    "    # 'sine1d',\n",
    "    # 'sine2d',\n",
    "    # 'flower',\n",
    "    # 'mnist',\n",
    "]\n",
    "    \n",
    "default_log = [\n",
    "    'noise',\n",
    "]\n",
    "\n",
    "d_pivots = {}\n",
    "index_columns = ['dataset_name'] + group_params\n",
    "dds = []\n",
    "dds_mean = []\n",
    "dds_std = []\n",
    "\n",
    "mins = []\n",
    "\n",
    "for dataset_name in datasets_predict:\n",
    "    d = df[df['tags'].astype(str).str.contains(f\"'{dataset_name}'\")].reset_index(drop=True)\n",
    "    d = d[~d['tags'].astype(str).str.contains(f'predict')].reset_index(drop=True)\n",
    "\n",
    "    d = stringify_dict(d, group_params)\n",
    "    ds = {group : d_group for group, d_group in d.groupby(group_params)} if group_params else {0 : d}\n",
    "\n",
    "\n",
    "    for group, d in ds.items():\n",
    "\n",
    "        d = d.reset_index(drop=True)\n",
    "\n",
    "        for row in d['data_kwargs']:\n",
    "            if 'grid_size' in row:\n",
    "                row['grid_size'] = tuple(row['grid_size'])\n",
    "        for row in d['transform_kwargs']:\n",
    "            if 'eps_mult' in row:\n",
    "                row['eps_mult'] = [float(x) for x in row['eps_mult']]\n",
    "\n",
    "        d = d.drop_duplicates(subset=hyper_params + ['seed', 'test_loss']) #TODO: why is this necessary?\n",
    "        map_kwargs = assert_columns_same(d, ['data_kwargs', 'transform_kwargs', 'data_dir'])\n",
    "\n",
    "        d_pivot = pivot(d, columns = hyper_params)\n",
    "        # d_pivot = rename_net(d_pivot)\n",
    "        d_pivots[(dataset_name, group)] = dict(d_pivot=d_pivot, map_kwargs=map_kwargs)\n",
    "\n",
    "        dd = pd.DataFrame(data = [f'{mean:.2e} ± {std:.2e}' for mean, std in zip(d_pivot.mean().values, d_pivot.std().values)], index = d_pivot.columns).T\n",
    "        dd_mean = pd.DataFrame(data = [mean for mean in d_pivot.mean().values], index = d_pivot.columns).T\n",
    "        dd_std = pd.DataFrame(data = [std for std in d_pivot.std().values], index = d_pivot.columns).T\n",
    "\n",
    "        for dd_i, dds_i in zip([dd, dd_mean, dd_std], [dds, dds_mean, dds_std]):\n",
    "\n",
    "            dd_i[index_columns] = [dataset_name] + list(group)\n",
    "            dd_i = dd_i.set_index(index_columns)\n",
    "            dds_i.append(dd_i)\n",
    "\n",
    "        # continue\n",
    "\n",
    "\n",
    "        hparams_min = d_pivot.mean().idxmin()\n",
    "        assert len(hparams_min) == 2\n",
    "        df_map_new = d[d[hyper_params[0]] == hparams_min[1]][df_map_columns]\n",
    "        add_df_map_new(df_map_new)\n",
    "        # Ps = get_and_check_Ps(df_map_new['seed'].unique(), map_kwargs)\n",
    "        # plot2d(Ps, l = 2, max_grid = 40)\n",
    "\n",
    "        print(f'{hparams_min=}')\n",
    "        mins.append((dataset_name, group, hparams_min))\n",
    "        logx = True if dataset_name in default_log else False\n",
    "        suptitle = dataset_name + '\\n' + ', '.join([f'{group_param} = {group_el}' for group_param, group_el in zip(group_params, group)]) if group != 0 else dataset_name\n",
    "#         plot_pivot(d_pivot=d_pivot, legend_loc = 'lower left', logx=logx, suptitle = suptitle, figsize = (4, 2))\n",
    "\n",
    "        break\n",
    "\n",
    "# ddd = pd.concat(dds)\n",
    "# ddd_mean = pd.concat(dds_mean)\n",
    "# ddd_std = pd.concat(dds_std)\n",
    "# ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.010</th>\n",
       "      <th>0.100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_loss                    \n",
       "lr       0.001     0.010     0.100\n",
       "seed                              \n",
       "1     0.000347  0.000062  0.000009\n",
       "2     0.000391  0.000061  0.000008\n",
       "3     0.000312  0.000061  0.000008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for logy in [False, True]:\n",
    "    ddd_mean.plot(kind='bar', yerr = ddd_std, figsize = (10, 5), logy = logy, rot = 45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.copy()\n",
    "\n",
    "d = d[~d['tags'].astype(str).str.contains('predict')].reset_index(drop=True)\n",
    "d = stringify_dict(d, group_params)\n",
    "\n",
    "dd = d.groupby(['data_dir'] + group_params + hyper_params + ['seed']).count()\n",
    "print(dd[dd['test_loss'] > 1].index.values)\n",
    "\n",
    "# d = d.pivot(index = ['data_dir'] + group_params , columns = hyper_params +  ['seed'], values = 'test_loss')\n",
    "\n",
    "d = pivot(d, index = ['data_dir'] + group_params, columns = hyper_params + ['seed'], values = 'test_loss')\n",
    "\n",
    "# d[d.isna().any(axis=0)]\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_pickle('../logs/store/map_df.pkl')\n",
    "df_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_tags(df, tags):\n",
    "    return df[df['tags'].astype(str).str.contains('|'.join(tags))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_pickle('../logs/store/map_df.pkl')\n",
    "\n",
    "df_map_sync = filter_on_tags(df_map, tags = ['sine1d', 'noise'])\n",
    "df_map_sync = df_map_sync.reset_index(drop=True)\n",
    "df_map_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_run_ids = list(df_map_sync['run_id'].values)\n",
    "\n",
    "store_dir = '../logs/store'\n",
    "# write the run_ids to a txt file\n",
    "with open(os.path.join(store_dir, 'sync_run_ids.txt'), 'w') as f:\n",
    "    f.write(f\"{{{','.join(sync_run_ids)}}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check Ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = df_map_sync\n",
    "d = df_map\n",
    "\n",
    "d = filter_on_tags(d, tags = ['noise'])\n",
    "\n",
    "transform_kwargs = {'eps_mult': [0.0, 1.0, 1.0, 1.0], 'only_flip': False}\n",
    "d = d[d['transform_kwargs'] == transform_kwargs]\n",
    "\n",
    "map_kwargs = assert_columns_same(d, ['data_kwargs', 'transform_kwargs', 'data_dir'])\n",
    "map_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ps = get_and_check_Ps(d['seed'].unique(), map_kwargs, use_P_from_noise = True)\n",
    "# Ps = get_and_check_Ps([1], map_kwargs)\n",
    "plot2d(Ps, l = 2, max_grid = 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sympde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
