{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../symlie'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '../sympdee/sympde/viz'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from symlie.model.networks.linear import CalculatedP, LinearP\n",
    "from sympdee.sympde.viz.general_plots import imshows, plot_vals, simple_imshow, savefig, simple_imshow, imshow\n",
    "from symlie.misc.utils_results import get_and_check_Ps, plot_seeds_and_Ps\n",
    "from symlie.data.transforms import Transform\n",
    "from symlie.model.networks.implicit import LinearImplicit\n",
    "from symlie.model.setup import load_implicitP_statedict\n",
    "from symlie.model.loss import mmd\n",
    "from symlie.run import parse_options, main, process_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2columns(x_plots, x_titles):\n",
    "\n",
    "    nrows = len(x_plots)\n",
    "    batch_size = x_plots[0][0].shape[0]\n",
    "\n",
    "    x_idx = np.random.randint(0, batch_size, 1)[0]\n",
    "    fig, axs = plt.subplots(nrows, 2, figsize = (6, 1.*nrows), tight_layout = True)\n",
    "    for i, (x_l, x_r) in enumerate(x_plots):\n",
    "\n",
    "        x_l, x_r = x_l.detach().cpu().numpy(), x_r.detach().cpu().numpy()\n",
    "\n",
    "        for j, (x_lr, color) in enumerate(zip([x_l, x_r], ['tab:blue', 'tab:orange'])):\n",
    "            xx = x_lr[x_idx]\n",
    "            ax = axs[i, j]\n",
    "            ax.plot(xx, 'o-', color = color)\n",
    "            ax.plot([len(xx)-1, len(xx)], [xx[-1], xx[0]], '--', color=color)\n",
    "            ax.plot([-1, 0], [xx[-1], xx[0]], '--', color=color)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([0])\n",
    "            ax.set_title(x_titles[i][j])\n",
    "    plt.show()\n",
    "\n",
    "def plot1d(x, logy = True, title = None):\n",
    "    plt.figure(figsize=(5,2))\n",
    "    plt.plot(x)\n",
    "    if logy: plt.yscale('log')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running without logging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elias/anaconda3/envs/sympde/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "args = parse_options(notebook=True)\n",
    "\n",
    "args.noise_std = 1.\n",
    "args.grid_size = (1, 7)\n",
    "args.eps_mult = [0.0, 0.0, 1.0, 0.0]\n",
    "args.net = 'TrainP'\n",
    "args.data_dir = '../data/sine1d'\n",
    "args.y_low = 1\n",
    "args.y_high = 3\n",
    "args.noise_std = 0.5\n",
    "\n",
    "args.do_return = True\n",
    "args.logger = None\n",
    "\n",
    "args.n_train = 100\n",
    "\n",
    "process_args(args)\n",
    "\n",
    "# Training\n",
    "_, _, datamodule = main(args)\n",
    "\n",
    "n_epochs = 100\n",
    "size = np.prod(args.grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = datamodule.train_dataloader()\n",
    "testloader = datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_funcs = {k: v() for k, v in CalculatedP(size = size).transform_funcs.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionLearner(nn.Module):\n",
    "    def __init__(self, size, method):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.method = method\n",
    "\n",
    "        self.weight1 = nn.Parameter(torch.rand(size, size))\n",
    "        self.bias1 = nn.Parameter(torch.rand(size))\n",
    "\n",
    "        match method:\n",
    "            case 'mlp':\n",
    "                self.f_eval = self.mlp\n",
    "                self.lossweights = [1, 1]\n",
    "            case 'none':\n",
    "                self.f_eval = self.vanilla\n",
    "                self.lossweights = [0,1]\n",
    "            case 'space_translation':\n",
    "                self.f_eval = self.space_translation\n",
    "                self.lossweights = [0,1]\n",
    "\n",
    "        features = size**2\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(features+size,size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(size,features+size),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(features,features),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(features,features),\n",
    "        )\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(size, 1, bias = False)\n",
    "\n",
    "    def mlp(self, weight, bias):\n",
    "        weight = weight.view(self.size**2)\n",
    "        weight_and_bias = torch.cat([weight, bias])\n",
    "        weight_and_bias = self.layers(weight_and_bias)\n",
    "        weight, bias = weight_and_bias[:self.size**2], weight_and_bias[self.size**2:]\n",
    "        weight = weight.view(self.size, self.size)\n",
    "        return weight, bias\n",
    "    \n",
    "    def vanilla(self, weight, bias):\n",
    "        return weight, bias\n",
    "        w = weight\n",
    "        w = w.view(size**2)\n",
    "        w = transform_funcs['none'] @ w\n",
    "        w = w.view(size, size)\n",
    "        return w\n",
    "    \n",
    "    def space_translation(self, weight):\n",
    "        w = weight\n",
    "        w = w.view(size**2)\n",
    "        w = transform_funcs['space_translation'] @ w\n",
    "        w = w.view(size, size)\n",
    "        return w\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        weight, bias = self.f_eval(self.weight1, self.bias1)\n",
    "\n",
    "        x = F.linear(x, weight, bias)\n",
    "\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "seed=41, method=none:   0%|          | 0/100 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m shift \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m*\u001b[39msize)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     40\u001b[0m weight, bias \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mweight1, mlp\u001b[38;5;241m.\u001b[39mbias1\n\u001b[0;32m---> 41\u001b[0m o_a \u001b[38;5;241m=\u001b[39m x_a \u001b[38;5;241m@\u001b[39m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m     42\u001b[0m o_a_prime \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mroll(o_a, shift, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m x_b_prime \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mroll(x_b, shift, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "seeds = [41, 42, 43]\n",
    "methods = ['none', 'space_translation', 'mlp']\n",
    "\n",
    "methods = ['none', 'mlp']\n",
    "\n",
    "\n",
    "rs = []\n",
    "for seed in seeds:\n",
    "  torch.manual_seed(seed)\n",
    "  for method in methods:\n",
    "\n",
    "    # Initialize the MLP\n",
    "    mlp = PredictionLearner(size=size, method=method)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion1     = nn.MSELoss()\n",
    "    criterion2     = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # Run the training loop\n",
    "    for epoch in tqdm(range(0, n_epochs), desc = f'seed={seed}, method={method}'):\n",
    "        \n",
    "        current_loss = 0.0\n",
    "        \n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "          \n",
    "            # Get inputs\n",
    "            x, y, _ = data\n",
    "            batch_size = x.size(0)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_b = x_a = torch.randn_like(x)\n",
    "            shift = (torch.rand((1))*size).int().item()\n",
    "\n",
    "            weight, bias = mlp.weight1, mlp.bias1\n",
    "            o_a = x_a @ mlp.f_eval(weight, bias).T\n",
    "            o_a_prime = torch.roll(o_a, shift, 1)\n",
    "\n",
    "            x_b_prime = torch.roll(x_b, shift, 1)\n",
    "            o_b_prime = x_b_prime @ mlp.f_eval(weight, bias).T\n",
    "\n",
    "            # Compute loss\n",
    "            loss1 = criterion1(o_a_prime, o_b_prime)\n",
    "\n",
    "\n",
    "            y_pred = mlp(x)\n",
    "\n",
    "\n",
    "            # Compute loss\n",
    "            loss2 = criterion2(y_pred, y)\n",
    "\n",
    "            loss = mlp.lossweights[0]*loss1 + mlp.lossweights[1]*loss2\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "        current_loss = current_loss / len(trainloader)\n",
    "        losses.append(current_loss)\n",
    "\n",
    "    mlp = mlp.eval()\n",
    "    test_loss = 0.0\n",
    "    y_trues, y_preds = [], []\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "      x, y, _ = data\n",
    "      y_pred = mlp(x)\n",
    "\n",
    "      loss = criterion2(y_pred, y)\n",
    "\n",
    "      test_loss += loss.item() / len(testloader)\n",
    "      y_trues.append(y.detach().squeeze(1))\n",
    "      y_preds.append(y_pred.detach().squeeze(1))\n",
    "\n",
    "    r = {\n",
    "        'seed': seed,\n",
    "        'method': method,\n",
    "        'test_loss': test_loss,\n",
    "        'losses': losses,\n",
    "    }\n",
    "    rs.append(r)\n",
    "\n",
    "    # plot1d(losses, logy = True, title = f'seed={seed}, loss={test_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp.layers.state_dict(), 'mlp_layers_state_dict.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.rand(size, size)\n",
    "\n",
    "weight = weight.view(size**2)\n",
    "weight = mlp.layers(weight)\n",
    "weight = weight.view(size, size)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow( weight.detach().cpu().numpy() )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(rs)\n",
    "results = results.set_index(['method']).sort_index()\n",
    "\n",
    "results_testloss = results.pivot(columns = 'seed', values = 'test_loss')\n",
    "results_losses = results.pivot(columns = 'seed', values = 'losses')\n",
    "\n",
    "results_testloss.plot(kind = 'bar', figsize = (5, 3), logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plots = len(results_losses)\n",
    "fig, axs = plt.subplots(1, n_plots, figsize = (3*n_plots, 3), tight_layout = True)\n",
    "for ax, (method, losses) in zip(axs, results_losses.iterrows()):\n",
    "    for losses_i in losses:\n",
    "        ax.plot(losses_i)\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_title(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_min, l_max = 0, 3\n",
    "plt.plot(torch.cat(y_trues), torch.cat(y_preds), '.', alpha = 0.1)\n",
    "plt.plot([l_min, l_max], [l_min, l_max], 'k--')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sympde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
